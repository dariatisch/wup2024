{
  "hash": "d24708071742080f1e6210117f0dbfb9",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat:\n  live-revealjs:\n    theme: default\n    slideNumber: true\n    chalkboard:\n      theme: whiteboard\n      boardmarker-width: 5\n      buttons: true\ntitle: \"1. Seminar\"\nsubtitle: \"Fortgeschrittene quantitative Methoden <br> Wintersemester 2024-2025\"\nauthor: \"Daria Tisch\"\nwebr:\n  cell-options:\n    autorun: true\n    fig-width: 11\n    fig-height: 5\n  webr:\n  packages:\n    - dplyr\n    - palmerpenguins\n    - ggplot2\n    - stevedata\n    - broom.helpers\neditor: visual\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Wie arbeiten wir in diesem Kurs?\n\n-   Vormittags: Seminar\n-   Nachmittags: Übung (Datenanalyse in R)\n-   [Kurswebsite](https://dariatisch.github.io/wup2024/)\n    -   Übersicht\n    -   Interaktive Präsentationen\n    -   Datensätze\n-   Fragen + Anregungen jederzeit erwünscht\n\n## Interaktive Folien\n\n\n\n\n\n::: {.cell}\n```{webr}\n2+2\n```\n:::\n\n\n\n\n\n## Interaktive Übungsaufgaben mit Lösungen\n\nBitte vervollständige den Code, sodass die Summe 10 ergibt.\n\n\n\n\n\n::: {.cell exercise='ex0' caption='Übung'}\n```{webr}\n#| exercise: ex0\n#| caption: Übung\n1 + 2 + 3 + ______\n```\n:::\n\n::: {.cell exercise='ex0' check='true'}\n```{webr}\n#| exercise: ex0\n#| check: true\nif (.result == 10) {\n  list(message = \"Hervorragend!\", correct = TRUE)\n} else {\n  list(message = \"Das ist leider falsch\", correct = FALSE)\n}\n```\n:::\n\n\n\n\n\n::: {.hint exercise=\"ex0\"}\nTipp: Rechne: 10-1-2-3\n:::\n\n::: {.solution exercise=\"ex1\"}\n::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n**Lösung:**\n\n``` r\n1 + 2 + 3 + 4\n```\n:::\n:::\n\n## Themen heute\n\n-   Forschungsdesigns\n-   Datenquellen\n-   Datenauswertung\n\nPflichtlektüre: Hinz, T. (2018). Methoden der Arbeitsmarktforschung (S. 479-524). In: Abraham, M., Hinz, T. (eds) Arbeitsmarktsoziologie. Springer VS, Wiesbaden.\n\n# Forschungsdesign\n\n## Forschungsdesign\n\n\"eine systematische, transparente sowie dem jeweiligen Forschungsproblem angemessene Vorgehensweise, um zu einer belastbaren Antwort auf die Forschungsfrage zu gelangen\" (S.480).\n\nForschungsfragen:\n\n-   Beschreibend\n\n-   Erklärend\n\nBeispiele?\n\n## Forschungsdesign {.smaller}\n\n1.  Beobachtungsdesign\n    -   Datenerhebung (Messung), Dokumentation, Auswertung\n    -   Explanandum (= zu erklärendes Phänomen) vom Forschungsprozess unabhängig\n    -   Zusammenhänge werden im Zuge des Forschungsprozesses \"entdeckt\"\n\n<!-- -->\n\n2.  Experimentaldesigns\n    -   Manipulation: Forscherin greift in den zu erklärenden Prozess ein\n    -   Experimentalgruppe erhält Treatment, Kontrollgruppe nicht\n    -   Randomisierte Zuteilung\n\n::: notes\nwarum nicht nur Experimentaldesigns?\n:::\n\n## Beobachtungsdesign\n\n-   Längsschnitt\n-   Querschnitt\n-   Beispiele?\n\n## Kausalanalyse mit Beobachtungsdesign {.smaller}\n\n-   Explanandum: Gender wage gap\n-   Konstanthaltung durch Drittvariablenkontrolle\n-   Probleme:\n    -   Endogenous selection bias\n    -   Omitted variable bias\n    -   Overcontrol bias\n    -   Collider Bias\n\n## Experimentaldesign\n\n-   Forscherin setzt experimentellen Stimulus (=Treatment)\n-   Randomisierte Zuteilung des Treatments schließt Einfluss von Drittvariablen aus\n-   Einfach Auswertung: Mittelwertunterschiede\n-   Für Identifikation von Kausaleffekten ist Randomisierung notwendig, aber keine Zufallsstichprobe. Warum trotzdem sinnvoll?\n\n::: notes\nExterne Validität\n:::\n\n## Experimentaldesigns\n\n-   Laborexperimente\n-   Feldexperimente\n-   Umfrageexperimente\n-   Natürliche Experimente (exogene Ereignisse sorgen für faktische Randomisierung eines Treatments)\n\n::: notes\nNatürliche Experimente: zB Gesetzesänderungen\n:::\n\n# Datenquellen\n\n## Datenquellen\n\n::: incremental\n-   Umfragedaten\n-   Prozessproduzierte Daten (aus administrativen Prozessen, die nicht zum Zweck der Forschung entstanden)\n-   Social Media\n-   Welche noch?\n:::\n\n## Umfragedaten\n\n::: incremental\nZufallsstichprobe - Wofür?\n\n-   Verallgemeinerbarkeit\n-   Repräsentativität\n-   Inferenzstatistik\n:::\n\n## Umfragedaten: Beispiele\n\n::: incremental\n-   Beispiele:\n    -   SOEP\n    -   Allbus\n    -   Neps\n    -   GESIS Panel\n    -   Mikrozensus\n:::\n\n## Umfragedaten: Inhalte\n\n::: incremental\n-   Einstellungen\n-   Biographien\n-   Einkommen und Vermögen\n:::\n\n## Umfragedaten mit experimentellen Teilen\n\n-   Factorial Survey Experimente\n-   Conjoint-Analysen\n-   Choice-Experimente\n\n::: notes\nBeispiele: - FS: Fair earings, just gender wage gao - Conjoint: Bsp: Attraktivität in der Partnerwahl, Prioritäten setzen, Trad-offs, Entscheidungen zwischen diskreten Alternativen -Choice: Befragte wählen aus verschiedenen (Handlungs-)Alternativen die von ihnen am meisten präferierte aus https://link.springer.com/article/10.1007/s11577-011-0136-3\n:::\n\n## Prozessproduzierte Daten {.smaller}\n\n= nicht für die sozialwissenschaftliche Analyse generierte Daten\n\n::: incremental\n-   Administrative Daten: Sozialversicherungen, Steuerdaten\n    -   Teilweise Verknüpfung mit Umfragedaten\n-   Fehlzeiten von Arbeitsnehmerinnen\n-   Internet Movie Base: Karriereinformationen\n-   Gerichtsakten\n-   Soziale Medien\n-   ...\n:::\n\n::: notes\nVorteile:objektiv (soziale Erwünschtheit kein Problem)\n:::\n\n# Datenauswertung\n\n## Datenauswertung\n\n1.  Beschreibung von erkennbaren Mustern in den Daten\n2.  Kausalschlüsse ziehen\n\n## Deskriptive Statistik\n\n-   Uni- und bivariate Statistik\n    -   Verteilungen von 1 bzw. 2 Variablen\n    -   Verteilungen werden durch Ausprägungen (=Antwortkategorien) gebildet\n    -   Eigenschaften von Verteilungen durch statistische Maßzahlen\n    -   Darstellung: Statistische Maßzahlen, Tabellen oder Diagramme\n\n# Los geht's mit angewandter Regressionsanalyse\n\n## Computational setup {.scrollable}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Packages\npkgs <- c(\n  \"stevedata\",\n  \"tidyverse\",\n  \"broom.helpers\",\n  \"ggplot2\"\n)\n\n## Install uninstalled packages\nlapply(pkgs[!(pkgs %in% installed.packages())], install.packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlist()\n```\n\n\n:::\n\n```{.r .cell-code}\n## Load all packages to library\nlapply(pkgs, library, character.only = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyverse' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tibble' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'readr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'purrr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'dplyr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'forcats' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'lubridate' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"stevedata\" \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\" \n[7] \"methods\"   \"base\"     \n\n[[2]]\n [1] \"lubridate\" \"forcats\"   \"stringr\"   \"dplyr\"     \"purrr\"     \"readr\"    \n [7] \"tidyr\"     \"tibble\"    \"ggplot2\"   \"tidyverse\" \"stevedata\" \"stats\"    \n[13] \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n[[3]]\n [1] \"broom.helpers\" \"lubridate\"     \"forcats\"       \"stringr\"      \n [5] \"dplyr\"         \"purrr\"         \"readr\"         \"tidyr\"        \n [9] \"tibble\"        \"ggplot2\"       \"tidyverse\"     \"stevedata\"    \n[13] \"stats\"         \"graphics\"      \"grDevices\"     \"utils\"        \n[17] \"datasets\"      \"methods\"       \"base\"         \n\n[[4]]\n [1] \"broom.helpers\" \"lubridate\"     \"forcats\"       \"stringr\"      \n [5] \"dplyr\"         \"purrr\"         \"readr\"         \"tidyr\"        \n [9] \"tibble\"        \"ggplot2\"       \"tidyverse\"     \"stevedata\"    \n[13] \"stats\"         \"graphics\"      \"grDevices\"     \"utils\"        \n[17] \"datasets\"      \"methods\"       \"base\"         \n```\n\n\n:::\n\n```{.r .cell-code}\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)\n```\n:::\n\n\n\n\n\n# Daten\n\n## GSS\n\n-   General Social Survey (1974-2018)\n-   Nur Einkommensdaten und ein paar weitere Variablen\n-   Package: stevedata\n\n## Daten Einlesen und Überblick\n\n-   prestg10: respondent's occupational prestige score\n-   realrinc: respondent's base income (in constant 1986 USD)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- stevedata::gss_wages %>% filter(year==2018) %>%\n  filter(!is.na(age)) %>% filter(!is.na(realrinc))\n         \nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,358\nColumns: 11\n$ year       <dbl> 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,…\n$ realrinc   <dbl> 45400.0, 54480.0, 8512.5, 17025.0, 908.0, 45400.0, 54480.0,…\n$ age        <dbl> 42, 63, 59, 43, 62, 55, 59, 34, 44, 75, 55, 40, 34, 40, 37,…\n$ occ10      <dbl> 1106, 3320, 3600, 5610, 4600, 6700, 10, 9120, 1720, 50, 325…\n$ occrecode  <chr> \"Professional\", \"Professional\", \"Service\", \"Office and Admi…\n$ prestg10   <dbl> 61, 59, 48, 35, 35, 39, 72, 35, 72, 53, 64, 64, 38, 64, 35,…\n$ childs     <dbl> 2, 2, 6, 0, 4, 2, 2, 3, 2, 4, 0, 2, 1, 1, 0, 3, 3, 0, 0, 5,…\n$ wrkstat    <chr> \"Full-Time\", \"Full-Time\", \"Full-Time\", \"Full-Time\", \"Full-T…\n$ gender     <chr> \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", \"Male…\n$ educcat    <chr> \"Bachelor\", \"Bachelor\", \"High School\", \"High School\", \"Less…\n$ maritalcat <chr> \"Married\", \"Married\", \"Divorced\", \"Never Married\", \"Widowed…\n```\n\n\n:::\n:::\n\n\n\n\n\n## Datenvisualisierung\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, \n       aes(x = age, y = log(realrinc))) +\n  geom_point(alpha = 0.5) + \n  labs(\n    x = \"Age\" , \n    y = \"Log(income)\"\n  )\n```\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-5-1.png){width=80%}\n:::\n:::\n\n\n\n\n\n# Regressionsmodel\n\n## Fit a line\n\n... um die Beziehung zwischen Alter und Einkommen zu *beschreiben*\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(data = df, \n            mapping = aes(x = age, y = log(realrinc))) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  labs(\n    x = \"Age\" , \n    y = \"Log(income)\"\n  )\n\np\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-6-1.png){width=70%}\n:::\n:::\n\n\n\n\n\n## Terminologie\n\n<center>X → Y</center>\n\n::: columns\n::: {.column width=\"30%\"}\n-   **Outcome, *Y***: Variable, die das Merkmal von Interesse beinhaltet\n-   **Predictor, X**: Variable, die uns hilft, die Varianz des Outcomes zu verstehen\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-7-1.png){width=100%}\n:::\n:::\n\n\n\n\n:::\n:::\n\n## Regressionsmodel\n\nEin **Regressionsmodel** ist eine Funktion, die den Zusammenhang zwischen dem Outcome, $Y$, und dem Prädiktor, $X$, beschreibt.\n\n$$\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}$$\n\n## Regressionsmodel\n\n::: columns\n::: {.column width=\"30%\"}\n$$\n  \\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \n\\end{aligned}\n$$\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(log(realrinc) ~ age, data = df)\ndf$predicted <- predict(m)\n\nggplot(data = df, \n       mapping = aes(x = age, y = log(realrinc))) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  labs(x = \"X\", y = \"Y\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks.x = element_blank(), \n    axis.ticks.y = element_blank()\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-8-1.png){width=80%}\n:::\n:::\n\n\n\n\n:::\n:::\n\n## Regressionsmodel + Residuen\n\n::: columns\n::: {.column width=\"30%\"}\n$$\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n\\end{aligned}$$\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-9-1.png){width=80%}\n:::\n:::\n\n\n\n\n:::\n:::\n\n# Einfache lineare Regression\n\n## Einfache lineare Regression\n\n$$\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}$$\n\n::: incremental\n-   $\\beta_1$: Wahrer slope der Beziehung zwischen $X$ und $Y$\n-   $\\beta_0$: Wahrer intercept der Beziehung zwischen $X$ und $Y$\n-   $\\epsilon$: Error (Residuen)\n:::\n\n## Einfache lineare Regression\n\n$$\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}$$\n\n-   $\\hat{\\beta}_1$: Geschätzter slope\n-   $\\hat{\\beta}_0$: Geschätzter intercept\n-   Kein Fehlerterm!\n\n## Residuen\n\n::: panel-tabset\n## Plot\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = df, mapping = aes(x = age, y = log(realrinc))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  geom_segment(aes(x = age, xend = age, y = log(realrinc), yend = predict(m)), color = \"steel blue\") +\n  labs(x = \"Alter\", y = \"Einkommen\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-10-1.png){width=80%}\n:::\n:::\n\n\n\n\n\n## Code\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = df, mapping = aes(x = age, y = log(realrinc))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  geom_segment(aes(x = age, xend = age, y = log(realrinc), yend = predict(m)), color = \"steel blue\") +\n  labs(x = \"Alter\", y = \"Einkommen\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_seminar_files/figure-html/unnamed-chunk-11-1.png){width=80%}\n:::\n:::\n\n\n\n\n:::\n\n$$\\text{Residuen} = \\text{Beobachted} - \\text{Vorhergesagt} = y - \\hat{y}$$\n\n::: notes\nSummer der Residuen = 0\n:::\n\n## Kleinstquadrate\n\n-   Residuum für die $i^{te}$ Beobachtung\n\n$$e_i = \\text{beobachtet} - \\text{vorhergesagt} = y_i - \\hat{y}_i$$\n\n-   Die Summe der quadrierten Residuen ist\n\n$$e^2_1 + e^2_2 + \\dots + e^2_n$$\n\n-   **Methode der kleinsten Quadrate** minimiert die Summe der quadratischen Residuen\n\n# Interpretation\n\n## Interpretation {.smaller}\n\n::: panel-tabset\n## Output\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_income <- lm(log(realrinc) ~ age, data = df)\nm_income   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(realrinc) ~ age, data = df)\n\nCoefficients:\n(Intercept)          age  \n    8.91235      0.01444  \n```\n\n\n:::\n:::\n\n\n\n\n\n## Code\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_income <- lm(log(realrinc) ~ age, data = df)\nm_income  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(realrinc) ~ age, data = df)\n\nCoefficients:\n(Intercept)          age  \n    8.91235      0.01444  \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n$$\\widehat{\\text{log(Einkommen)}} = 8.91 + 0.01 \\times \\text{Alter}$$\n\n::: incremental\n-   **Slope:** Für jedes zusätzliche Jahr im Alter erwarten wir eine Vergrößerung des logarithmierten Wertes des Einkommens um 0.01 oder: Für jedes zusätzliche Jahr im Alter erwarten wir einen Einkommensanstieg von etwa 1.005% ($(e^{0.01} - 1) \\times 100$)\n:::\n\n## Interpretation {.smaller}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_income <- lm(log(realrinc) ~ age, data = df)\nm_income    \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(realrinc) ~ age, data = df)\n\nCoefficients:\n(Intercept)          age  \n    8.91235      0.01444  \n```\n\n\n:::\n:::\n\n\n\n\n\n$$\\widehat{\\text{log(Einkommen)}} = 8.91 + 0.01 \\times \\text{Alter}$$\n\n::: incremental\n-   **Intercept:** Eine Person mit 0 Jahren hat ein durchschnittliches log. Einkommen von 8.91. Sinnvoll?\n:::\n\n## Vorhersagen machen {.smaller}\n\nJemand ist 28 Jahre alt. Wie hoch ist nach diesem Modell das Einkommen?\n\n::: panel-tabset\n## Händisch\n\n$$\n\\begin{aligned}\n\\widehat{\\text{log(income)}} &= 8.91 + 0.01 \\times \\text{age} \\\\\n&= 8.91 + 0.01 \\times 28 \\\\\n&= 9.19\n\\end{aligned}\n$$\n\n## in R\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a new data frame for age = 28\nnew_data <- data.frame(age = 28)\n\n\n# Predict log(realrinc) for age = 28\npredicted_log_income <- predict(m_income, newdata = new_data)\n\n# Optionally reverse the log transformation\npredicted_real_income <- exp(predicted_log_income)\n\n# View results\npredicted_log_income  # log(realrinc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1 \n9.316802 \n```\n\n\n:::\n\n```{.r .cell-code}\npredicted_real_income # real income\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1 \n11123.35 \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## OLS Regression: Annahmen {.smaller}\n\n1.  **Funktionaler** linearer Zusammenhang der UV und AV (linear in parameters)\n2.  AV ist metrisch\\\n3.  Keine Multikollinearität der UVs\n4.  Normalverteilung der Residuen\n5.  Homoskedastizität der Residuen: $\\text{Var}(\\epsilon|X) = \\text{const}$.\n6.  Residuen haben einen Mittelwert von 0: $\\text{E}(\\varepsilon|X) = 0$.\n7.  Strikte Exogenitätsannahme: $\\text{Cov}(\\varepsilon|X) = 0$.\n8.  Zufallsstichprobe (Inferenzstatistik)\n9.  Keine Messfehler\n\n::: notes\n4-6: Verletzung führt zu verzerrten Standardfehlern (fehlerhafte Signifikanztests und Konfidenzintervalle)  ineffizient Verletzung führt nicht zu verzerrten Regressionskoeffizienten  konsistent 7:Verletzung führt zu verzerrten Regressionskoeffizienten und Standardfehlern (ineffizient und inkonsistent) Theoretische Modellspezifikation: „\\[Das Modell\\] muss also einerseits alle bedeutsamen unabhängigen Variablen enthalten und darf keine für die Erklärung der abhängigen Variablen irrelevanten unabhängigen Variablen enthalten.“ -\\> „omitted variable bias“ / unbeobachtete Heterogenität\n:::\n\n## Exkurs: Variablen und Skalenniveaus {.smaller}\n\n::: incremental\n-   Verhältnis (Rangordnung, Abstände und Verhältnisse, absoluter Nullpunkt)\n    -   Einkommen\n    -   Alter\n-   Intervallskala (Rangordnung und Abstände)\n    -   Grad Celsius\n    -   Geburtsjahr\n-   Ordinales Skalenniveau (Rangordnung)\n    -   Schulnoten\n    -   Zufriedenheit\n-   Nominalskala (gleich/ungleich)\n    -   Blutgruppe\n    -   Familienname\n:::\n\n<!-- ## Nun wird es noch praktischer -->\n\n<!-- ```{webr} -->\n\n<!-- ## Packages -->\n\n<!-- pkgs <- c( -->\n\n<!--   \"tidyverse\", -->\n\n<!--   \"tidymodels\", -->\n\n<!--   \"stevedata\" -->\n\n<!-- ) -->\n\n<!-- ## Install uninstalled packages -->\n\n<!-- lapply(pkgs[!(pkgs %in% installed.packages())], install.packages) -->\n\n<!-- ## Load all packages to library -->\n\n<!-- lapply(pkgs, library, character.only = TRUE) -->\n\n<!-- ``` -->\n\n# Nun wird es noch praktischer\n\n## Regression {.smaller}\n\nBitte ermittle anhand einer Regression den durchschnittlichen Geschlechterspezifischen Lohnunterschied.\n\n::: panel-tabset\n## Übung\n\n\n\n\n\n::: {.cell caption='Übung Geschlechterunterschied' exercise='ex1' check='false'}\n```{webr}\n#| caption: Übung Geschlechterunterschied\n#| exercise: ex1\n#| check: false\nlibrary(\"stevedata\")\ndf <- stevedata::gss_wages %>% filter(year==2018) %>%\n  filter(!is.na(age)) %>% filter(!is.na(realrinc))\n\n# Lineare Regression\nmodel <- lm(______ ~ ______, data = df)\n\n# Zusammenfassung der Regressionsergebnisse\nsummary(model)\n\n# Ergebnisse übersichtlich darstellen\nbroom::tidy(model)\n\n```\n:::\n\n\n\n\n\n## Tipp\n\n::: {.hint exercise=\"ex1\"}\nDu brauchst die Variablen Geschlecht und Einkommen. Du findest sie, wenn Du Die alle Variablen anzeigen lässt:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"       \"realrinc\"   \"age\"        \"occ10\"      \"occrecode\" \n [6] \"prestg10\"   \"childs\"     \"wrkstat\"    \"gender\"     \"educcat\"   \n[11] \"maritalcat\" \"predicted\" \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## Lösung\n\n::: {.solution exercise=\"ex1\"}\n**Lösung:z.B.**\n\n\n\n\n\n::: {.cell exercise='ex1' solution='true'}\n```{webr}\n#| exercise: ex1\n#| solution: true\nlibrary(\"stevedata\")\ndf <- stevedata::gss_wages %>% filter(year==2018) %>%\n  filter(!is.na(age)) %>% filter(!is.na(realrinc))\n\n# Lineare Regression\nmodel <- lm(realrinc ~ gender, data = df)\n\n# Zusammenfassung der Regressionsergebnisse\nsummary(model)\n\n# Ergebnisse übersichtlich darstellen\nbroom::tidy(model)\n```\n:::\n\n\n\n\n:::\n:::\n\n## Geschlechterunterschiede im Einkommen {.smaller}\n\n### Graphische Darstellung\n\nBitte stelle Geschlechterunterschiede im Einkommen Graphisch dar.\n\n::: panel-tabset\n## Übung\n\n\n\n\n\n::: {.cell exercise='ex2' check='false'}\n```{webr}\n#| exercise: ex2\n#| check: false\ndf <- stevedata::gss_wages %>% filter(year==2018) %>%\n  filter(!is.na(age)) %>% filter(!is.na(realrinc))\n\nggplot(df, aes(x = ______, y = realrinc, fill = ______)) +\n  geom_violin(trim = FALSE) +\n  labs(\n    title = \"Geschlechterunterschiede beim Einkommen (2018)\",\n    x = \"Geschlecht\",\n    y = \"Reales Einkommen\",\n    fill = \"Geschlecht\"\n  ) +\n  theme_minimal()\n\n```\n:::\n\n\n\n\n\n## Tipp\n\n::: {.hint exercise=\"ex2\"}\nThe gesuchte Variable lautet: gender\n:::\n\n::: {.hint exercise=\"ex2\"}\nDas findest Du heraus, indem Du dir die Daten anschaust\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"       \"realrinc\"   \"age\"        \"occ10\"      \"occrecode\" \n [6] \"prestg10\"   \"childs\"     \"wrkstat\"    \"gender\"     \"educcat\"   \n[11] \"maritalcat\" \"predicted\" \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## Lösung\n\n::: {.solution exercise=\"ex2\"}\n**Lösung:**\n\nEin Beispiel:\n\n\n\n\n\n::: {.cell exercise='ex2' solution='true'}\n```{webr}\n#| exercise: ex2\n#| solution: true\ndf <- stevedata::gss_wages %>% filter(year==2018) %>%\n  filter(!is.na(age)) %>% filter(!is.na(realrinc))\nggplot(df, aes(x = gender, y = realrinc, fill = gender)) +\n  geom_violin(trim = FALSE) +\n  labs(\n    title = \"Geschlechterunterschiede beim Einkommen (2018)\",\n    x = \"Geschlecht\",\n    y = \"Reales Einkommen\",\n    fill = \"Geschlecht\"\n  ) +\n  theme_minimal()\n\n```\n:::\n\n\n\n\n:::\n:::\n\n## Ende\n\n-   Dieser Foliensatz profitierte in großen Teilen von ehemaligen Veranstaltungen von Isabel Habicht sowie von:\n    -   https://sta210-s22.github.io/website/slides/lec-2.html#/title-slide\n-   Weiterführende Informationen:\n    -   Hinz, T. (2018). Methoden der Arbeitsmarktforschung (S. 479-524). In: Abraham, M., Hinz, T. (eds) Arbeitsmarktsoziologie. Springer VS, Wiesbaden.\n",
    "supporting": [
      "1_seminar_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}